# ğŸ§  NLP Text Classifier API (Multitask + Multilabel)

## ğŸ” Project Overview

This project implements a production-ready pipeline for classifying user comments by:
- **Sentiment**: Positive / Negative
- **Level 1 category**: High-level complaint types (e.g. Prices, Cleanliness, Loyalty Program)
- **Level 2 category**: Fine-grained subcategories (up to 70+ types)

The system is designed to be lightweight and interpretable, serving as an alternative to heavy LLM-based models.

---

## ğŸ—ï¸ Project Architecture

```
nlp_project/
â”‚
â”œâ”€â”€ data/                   # Raw data (not included in Git)
â”‚
â”œâ”€â”€ models/                 # Trained model files (.h5, .joblib)
â”‚   â”œâ”€â”€ tone_model.h5
â”‚   â”œâ”€â”€ level1_model.h5
â”‚   â””â”€â”€ level2_model.h5
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py    # Text cleaning, tokenization, lemmatization
â”‚   â”œâ”€â”€ train.py            # Training pipeline for tone, level 1, level 2
â”‚   â””â”€â”€ predict.py          # Full pipeline for text classification
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py             # FastAPI server for predictions
â”‚
â”œâ”€â”€ notebooks/              # EDA, modeling, and experiments
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_modeling_lstm.ipynb
â”‚   â””â”€â”€ 03_multitask_modeling.ipynb
â”‚
â”œâ”€â”€ tests/                  # Unit tests
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Features

- âœ… **Text Preprocessing**: Stopwords removal, lemmatization, tokenization
- âœ… **Multilabel Output**: Classifies multiple categories per comment
- âœ… **Multitask Pipeline**: Level 2 depends on predicted Level 1
- âœ… **LSTM Neural Networks**: Efficient model training on modest hardware
- âœ… **FastAPI Serving**: Simple and scalable prediction interface
- âœ… **BERT (optional)**: Ready-to-extend with transformer models

---

## ğŸš€ Running the Project

### 1. Install Dependencies

```bash
python -m venv venv
venv\Scripts\activate  # or source venv/bin/activate on Unix
pip install -r requirements.txt
```

### 2. Train All Models

```bash
python src/train.py
```

This will generate 3 model files in the `/models` directory.

### 3. Start the API

```bash
uvicorn api.main:app --reload
```

Docs available at: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ”® Inference Example

You can send a comment to the API and receive a full structured response:

```json
{
  "text": "Ğ¦ĞµĞ½Ñ‹ Ğ²Ñ‹Ñ€Ğ¾ÑĞ»Ğ¸, ĞºĞ°ÑÑĞ¸Ñ€ Ñ…Ğ°Ğ¼Ğ¸Ñ‚ Ğ¸ ÑĞºĞ¸Ğ´ĞºĞ¸ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚",
  "tone": "Negative",
  "level_1": ["Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ñ†ĞµĞ½", "Ğ’ĞµĞ¶Ğ»Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ Ğ¸ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ°", "Ğ¡ĞºĞ¸Ğ´ĞºĞ¸ Ğ¸ Ğ°ĞºÑ†Ğ¸Ğ¸"],
  "level_2": ["ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ Ñ†ĞµĞ½Ñ‹", "Ğ“Ñ€ÑƒĞ±Ğ¾ÑÑ‚ÑŒ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ°", "ĞÑ‚ĞºĞ°Ğ· Ğ² ÑĞºĞ¸Ğ´ĞºĞµ"]
}
```

---

## ğŸ“Š Model Evaluation

| Task       | Accuracy / Recall | Model Type     |
|------------|-------------------|----------------|
| Tone       | 93.2%             | LSTM           |
| Level 1    | 89% micro recall  | LSTM multilabel|
| Level 2    | ~76% recall       | LSTM + Level 1 |
| BERT       | *Not deployed*    | Optional       |

---

## ğŸ“¦ Requirements

All dependencies are listed in `requirements.txt`.

Optional GPU acceleration possible with TensorFlow (>=2.11.0).

---

## ğŸ§ª Testing

```bash
pytest tests/
```

---

## ğŸ” Notes

- Dataset is not included due to privacy/compliance. Add your labeled `.csv` to `/data/raw`.
- `.gitignore` ensures models, logs, and virtual env are not pushed.

---

## ğŸ“ Future Plans

- [ ] Add Telegram/Slack alerting for failed predictions
- [ ] Explore Quantization & Distillation of large models
- [ ] Add real-time logging with Grafana/Prometheus
- [ ] Switch to `LLama` or `ruGPT-3` for heavy tasks

---

## ğŸ‘¨â€ğŸ’» Author

Built by [Your Name] as a lean alternative to LLMs for Russian-language classification in production environments.
